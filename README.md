# CMT-and-ViT-models-in-Medical-Image-Classification

# This is a course project about the expirical evaulation of two models - Convolutional Neural Networks Meet Vision Transformers (CMT) and Vision Transformers (ViT) in medical image classification tasks, focusing on chest X-ray datasets. Specifically, the project evaluates and compares the ViT-Tiny, ViT-Small, and CMT using different attention mechanisms: standard self-attention, sparse attention, and local attention.

# The primary objective is to determine which model and attention mechanism combination offers the best accuracy, computational efficiency, and resource utilization in classifying medical images. The project uses the COVID-19 Chest X-ray Dataset and the NIH Chest X-ray Dataset, implementing extensive experiments to analyze how different models perform across various metrics.
